{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸš€ SuperIa Project - Notebook Colab\n",
        "Architecture fonctionnelle intÃ©grant 24 briques open-source pour RL, HDC, AutoML, MLOps, UI/UX."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone le projet SuperIa\n",
        "!git clone https://github.com/AdaoJOAQUIM/SuperIa_Project.git\n",
        "%cd SuperIa_Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Installation des dÃ©pendances\n",
        "!pip install -r requirements.txt -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# VÃ©rification GPU\n",
        "import torch\n",
        "print(f'PyTorch version: {torch.__version__}')\n",
        "print(f'CUDA available: {torch.cuda.is_available()}')\n",
        "if torch.cuda.is_available():\n",
        "    print(f'GPU: {torch.cuda.get_device_name(0)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test imports modules\n",
        "import transformers\n",
        "import sklearn\n",
        "import optuna\n",
        "import mlflow\n",
        "print('All core modules imported successfully!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŽ¯ PrÃªt pour l'exÃ©cution!\n",
        "Le projet SuperIa est maintenant configurÃ©. Vous pouvez exÃ©cuter vos pipelines RL, AutoML, et plus."
      ]
    }
  ]
}
